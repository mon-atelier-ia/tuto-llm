{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecon 2 : Apprendre de ses erreurs\n",
    "\n",
    "## Le secret de l'IA : se tromper, corriger, recommencer\n",
    "\n",
    "Imagine que tu apprends a lancer une balle dans un panier :\n",
    "1. Tu lances -> tu rates a droite\n",
    "2. Tu corriges un peu a gauche\n",
    "3. Tu relances -> plus pres !\n",
    "4. Tu continues jusqu'a marquer\n",
    "\n",
    "L'IA fait **exactement** pareil. Elle fait une prediction, regarde si c'est\n",
    "bon, et ajuste. Ca s'appelle **l'entrainement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1 : Mesurer l'erreur\n",
    "\n",
    "D'abord, il faut un moyen de dire **a quel point** le modele s'est trompe.\n",
    "On appelle ca la **loss** (perte en anglais).\n",
    "\n",
    "- Loss haute = le modele se trompe beaucoup\n",
    "- Loss basse = le modele devine bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Imaginons que le modele predit les probabilites suivantes\n",
    "# pour la lettre qui suit 'h' dans le prenom 'hugo' :\n",
    "\n",
    "prediction = {\n",
    "    'u': 0.6,   # 60% -> bonne reponse !\n",
    "    'a': 0.2,   # 20%\n",
    "    'e': 0.15,  # 15%\n",
    "    'o': 0.05,  # 5%\n",
    "}\n",
    "\n",
    "# La bonne reponse est 'u'\n",
    "bonne_reponse = 'u'\n",
    "\n",
    "# La loss = a quel point on est surpris par la bonne reponse\n",
    "# Si on avait dit 100% pour 'u', la surprise serait de 0 (parfait !)\n",
    "# Si on avait dit 1% pour 'u', la surprise serait enorme\n",
    "\n",
    "loss = -math.log(prediction[bonne_reponse])\n",
    "print(f\"Le modele donnait {prediction[bonne_reponse]:.0%} de chance a '{bonne_reponse}'\")\n",
    "print(f\"Loss = {loss:.2f}\")\n",
    "print()\n",
    "\n",
    "# Comparons avec une mauvaise prediction\n",
    "mauvaise_prediction = {'u': 0.05, 'a': 0.7, 'e': 0.2, 'o': 0.05}\n",
    "loss_mauvaise = -math.log(mauvaise_prediction[bonne_reponse])\n",
    "print(f\"Si le modele n'avait donne que {mauvaise_prediction[bonne_reponse]:.0%} a '{bonne_reponse}'...\")\n",
    "print(f\"Loss = {loss_mauvaise:.2f}  (beaucoup plus haut = beaucoup plus faux)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2 : Les poids du modele\n",
    "\n",
    "Un modele, c'est juste une collection de **nombres** (on les appelle des **poids**).\n",
    "Ces nombres determinent les predictions.\n",
    "\n",
    "Entrainer = trouver les bons nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# On cree un mini-modele : juste des scores pour chaque paire de lettres\n",
    "# Au debut, les scores sont aleatoires -> le modele ne sait rien\n",
    "\n",
    "alphabet = list(\"abcdefghijklmnopqrstuvwxyz.\")\n",
    "\n",
    "# Scores aleatoires (les \"poids\" du modele)\n",
    "random.seed(42)\n",
    "poids = {}\n",
    "for a in alphabet:\n",
    "    poids[a] = {}\n",
    "    for b in alphabet:\n",
    "        poids[a][b] = random.uniform(-1, 1)\n",
    "\n",
    "def calculer_probas(poids, lettre):\n",
    "    \"\"\"Transforme les scores en probabilites (softmax).\"\"\"\n",
    "    scores = poids[lettre]\n",
    "    # L'exponentielle rend tous les scores positifs\n",
    "    exps = {b: math.exp(scores[b]) for b in scores}\n",
    "    total = sum(exps.values())\n",
    "    return {b: exps[b] / total for b in scores}\n",
    "\n",
    "# Au debut, les probas sont quasi uniformes (le modele devine au hasard)\n",
    "p = calculer_probas(poids, '.')\n",
    "lettres_debut = sorted(p.items(), key=lambda x: -x[1])[:5]\n",
    "print(\"Au debut, le modele pense que les prenoms commencent par :\")\n",
    "for lettre, prob in lettres_debut:\n",
    "    print(f\"  '{lettre}' : {prob:.1%}\")\n",
    "print(\"\\n  -> C'est n'importe quoi ! Il faut l'entrainer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3 : Entrainement\n",
    "\n",
    "L'algorithme est simple :\n",
    "1. Prendre un prenom d'entrainement\n",
    "2. Le modele fait sa prediction\n",
    "3. On calcule la loss (l'erreur)\n",
    "4. On **ajuste les poids** pour reduire la loss\n",
    "5. Recommencer\n",
    "\n",
    "L'etape 4 s'appelle la **descente de gradient**. C'est comme ajuster ton\n",
    "tir au panier un petit peu a chaque essai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prenoms = [\n",
    "    \"emma\", \"lucas\", \"lea\", \"hugo\", \"chloe\",\n",
    "    \"louis\", \"alice\", \"jules\", \"lina\", \"adam\",\n",
    "    \"rose\", \"arthur\", \"manon\", \"paul\", \"jade\",\n",
    "    \"nathan\", \"eva\", \"leo\", \"clara\", \"noah\",\n",
    "]\n",
    "\n",
    "# Vitesse d'apprentissage : de combien on ajuste a chaque fois\n",
    "# Trop grand = on depasse, trop petit = on apprend trop lentement\n",
    "vitesse = 0.1\n",
    "\n",
    "print(\"Entrainement...\")\n",
    "print()\n",
    "\n",
    "for epoch in range(50):\n",
    "    loss_totale = 0\n",
    "    nb = 0\n",
    "\n",
    "    for prenom in prenoms:\n",
    "        mot = \".\" + prenom + \".\"\n",
    "        for i in range(len(mot) - 1):\n",
    "            lettre = mot[i]\n",
    "            cible = mot[i + 1]\n",
    "\n",
    "            # 1. Prediction\n",
    "            probas = calculer_probas(poids, lettre)\n",
    "\n",
    "            # 2. Loss\n",
    "            loss_totale += -math.log(probas[cible] + 1e-10)\n",
    "            nb += 1\n",
    "\n",
    "            # 3. Ajuster les poids (gradient simplifie)\n",
    "            for b in alphabet:\n",
    "                if b == cible:\n",
    "                    # La bonne reponse : augmenter son score\n",
    "                    poids[lettre][b] += vitesse * (1 - probas[b])\n",
    "                else:\n",
    "                    # Les mauvaises reponses : baisser leur score\n",
    "                    poids[lettre][b] -= vitesse * probas[b]\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"  Epoch {epoch:2d} | Loss moyenne : {loss_totale / nb:.3f}\")\n",
    "\n",
    "print(f\"  Epoch {epoch:2d} | Loss moyenne : {loss_totale / nb:.3f}\")\n",
    "print()\n",
    "print(\"La loss baisse = le modele s'ameliore !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voyons maintenant ce que le modele a appris :\n",
    "p = calculer_probas(poids, '.')\n",
    "lettres_debut = sorted(p.items(), key=lambda x: -x[1])[:5]\n",
    "print(\"Apres entrainement, les prenoms commencent par :\")\n",
    "for lettre, prob in lettres_debut:\n",
    "    print(f\"  '{lettre}' : {prob:.1%}\")\n",
    "print()\n",
    "print(\"C'est plus logique ! (l, a, e, c, j sont des debuts courants)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generons des prenoms avec le modele entraine\n",
    "def generer(poids, n=10):\n",
    "    resultats = []\n",
    "    for _ in range(n):\n",
    "        prenom = \"\"\n",
    "        lettre = \".\"\n",
    "        for _ in range(20):  # max 20 lettres\n",
    "            p = calculer_probas(poids, lettre)\n",
    "            choix = list(p.keys())\n",
    "            probs = list(p.values())\n",
    "            lettre = random.choices(choix, weights=probs, k=1)[0]\n",
    "            if lettre == \".\":\n",
    "                break\n",
    "            prenom += lettre\n",
    "        if prenom:\n",
    "            resultats.append(prenom.capitalize())\n",
    "    return resultats\n",
    "\n",
    "print(\"Prenoms inventes apres entrainement :\")\n",
    "for p in generer(poids, 10):\n",
    "    print(f\"  {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce qu'on a appris\n",
    "\n",
    "- La **loss** mesure a quel point le modele se trompe\n",
    "- Les **poids** sont les nombres que le modele ajuste pour apprendre\n",
    "- L'**entrainement** = ajuster les poids pour reduire la loss, encore et encore\n",
    "- Meme un modele simple s'ameliore avec l'entrainement !\n",
    "\n",
    "### Limite\n",
    "\n",
    "Notre modele ne regarde encore que **1 lettre en arriere**.\n",
    "Dans la prochaine lecon, on va lui donner une **memoire** pour qu'il\n",
    "se souvienne de plusieurs lettres a la fois.\n",
    "\n",
    "---\n",
    "*Prochaine lecon : [03 - La memoire du modele](03_la_memoire_du_modele.ipynb)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
