{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leçon 2 : Apprendre de ses erreurs\n",
    "\n",
    "## Le secret de l'IA : se tromper, corriger, recommencer\n",
    "\n",
    "Imagine que tu apprends à lancer une balle dans un panier :\n",
    "1. Tu lances -> tu rates à droite\n",
    "2. Tu corriges un peu à gauche\n",
    "3. Tu relances -> plus près !\n",
    "4. Tu continues jusqu'à marquer\n",
    "\n",
    "L'IA fait **exactement** pareil. Elle fait une prédiction, regarde si c'est\n",
    "bon, et ajuste. Ça s'appelle **l'entraînement**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : Mesurer l'erreur\n",
    "\n",
    "D'abord, il faut un moyen de dire **à quel point** le modèle s'est trompé.\n",
    "On appelle ça la **loss** (perte en anglais).\n",
    "\n",
    "- Loss haute = le modèle se trompe beaucoup\n",
    "- Loss basse = le modèle devine bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import math\n\n# Imaginons que le modèle prédit les probabilités suivantes\n# pour la lettre qui suit 'p' dans 'pikachu' :\n\nprediction = {\n    \"i\": 0.6,  # 60% -> bonne réponse !\n    \"a\": 0.2,  # 20%\n    \"e\": 0.15,  # 15%\n    \"o\": 0.05,  # 5%\n}\n\n# La bonne réponse est 'i'\nbonne_reponse = \"i\"\n\n# La loss = à quel point on est surpris par la bonne réponse\n# Si on avait dit 100% pour 'i', la surprise serait de 0 (parfait !)\n# Si on avait dit 1% pour 'i', la surprise serait énorme\n\nloss = -math.log(prediction[bonne_reponse])\nprint(\n    f\"Le modèle donnait {prediction[bonne_reponse]:.0%} de chance à '{bonne_reponse}'\"\n)\nprint(f\"Loss = {loss:.2f}\")\nprint()\n\n# Comparons avec une mauvaise prédiction\nmauvaise_prediction = {\"i\": 0.05, \"a\": 0.7, \"e\": 0.2, \"o\": 0.05}\nloss_mauvaise = -math.log(mauvaise_prediction[bonne_reponse])\nprint(\n    f\"Si le modèle n'avait donné que {mauvaise_prediction[bonne_reponse]:.0%} à '{bonne_reponse}'...\"\n)\nprint(f\"Loss = {loss_mauvaise:.2f}  (beaucoup plus haut = beaucoup plus faux)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2 : Les poids du modèle\n",
    "\n",
    "Un modèle, c'est juste une collection de **nombres** (on les appelle des **poids**).\n",
    "Ces nombres déterminent les prédictions.\n",
    "\n",
    "Entraîner = trouver les bons nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import math\nimport random\n\n# On crée un mini-modèle : juste des scores pour chaque paire de lettres\n# Au début, les scores sont aléatoires -> le modèle ne sait rien\n\nalphabet = list(\"abcdefghijklmnopqrstuvwxyz.\")\n\n# Scores aléatoires (les \"poids\" du modèle)\nrandom.seed(42)\npoids = {}\nfor a in alphabet:\n    poids[a] = {}\n    for b in alphabet:\n        poids[a][b] = random.uniform(-1, 1)\n\n\ndef calculer_probas(poids, lettre):\n    \"\"\"Transforme les scores en probabilités (softmax).\"\"\"\n    scores = poids[lettre]\n    # L'exponentielle rend tous les scores positifs\n    exps = {b: math.exp(scores[b]) for b in scores}\n    total = sum(exps.values())\n    return {b: exps[b] / total for b in scores}\n\n\n# Au début, les probas sont quasi uniformes (le modèle devine au hasard)\np = calculer_probas(poids, \".\")\nlettres_debut = sorted(p.items(), key=lambda x: -x[1])[:5]\nprint(\"Au début, le modèle pense que les Pokémon commencent par :\")\nfor lettre, prob in lettres_debut:\n    print(f\"  '{lettre}' : {prob:.1%}\")\nprint(\"\\n  -> C'est n'importe quoi ! Il faut l'entraîner.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Étape 3 : Entraînement\n\nL'algorithme est simple :\n1. Prendre un nom de Pokémon d'entraînement\n2. Le modèle fait sa prédiction\n3. On calcule la loss (l'erreur)\n4. On **ajuste les poids** pour réduire la loss\n5. Recommencer\n\nL'étape 4 s'appelle la **descente de gradient**. C'est comme ajuster ton\ntir au panier un petit peu à chaque essai."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "pokemons = [\n    \"arcanin\",\n    \"bulbizarre\",\n    \"carapuce\",\n    \"dracaufeu\",\n    \"ectoplasma\",\n    \"evoli\",\n    \"felinferno\",\n    \"gardevoir\",\n    \"goupix\",\n    \"lokhlass\",\n    \"lucario\",\n    \"metamorph\",\n    \"mewtwo\",\n    \"noctali\",\n    \"pikachu\",\n    \"rondoudou\",\n    \"ronflex\",\n    \"salameche\",\n    \"togepi\",\n    \"voltali\",\n]\n\n# Vitesse d'apprentissage : de combien on ajuste à chaque fois\n# Trop grand = on dépasse, trop petit = on apprend trop lentement\nvitesse = 0.1\n\nprint(\"Entraînement...\")\nprint()\n\nfor epoch in range(50):\n    loss_totale = 0\n    nb = 0\n\n    for pokemon in pokemons:\n        mot = \".\" + pokemon + \".\"\n        for i in range(len(mot) - 1):\n            lettre = mot[i]\n            cible = mot[i + 1]\n\n            # 1. Prédiction\n            probas = calculer_probas(poids, lettre)\n\n            # 2. Loss\n            loss_totale += -math.log(probas[cible] + 1e-10)\n            nb += 1\n\n            # 3. Ajuster les poids (gradient simplifié)\n            for b in alphabet:\n                if b == cible:\n                    # La bonne réponse : augmenter son score\n                    poids[lettre][b] += vitesse * (1 - probas[b])\n                else:\n                    # Les mauvaises réponses : baisser leur score\n                    poids[lettre][b] -= vitesse * probas[b]\n\n    if epoch % 10 == 0:\n        print(f\"  Epoch {epoch:2d} | Loss moyenne : {loss_totale / nb:.3f}\")\n\nprint(f\"  Epoch {epoch:2d} | Loss moyenne : {loss_totale / nb:.3f}\")\nprint()\nprint(\"La loss baisse = le modèle s'améliore !\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Voyons maintenant ce que le modèle a appris :\np = calculer_probas(poids, \".\")\nlettres_debut = sorted(p.items(), key=lambda x: -x[1])[:5]\nprint(\"Après entraînement, les Pokémon commencent par :\")\nfor lettre, prob in lettres_debut:\n    print(f\"  '{lettre}' : {prob:.1%}\")\nprint()\nprint(\"C'est plus logique ! (c, m, g, e, r sont des débuts courants)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Générons des noms de Pokémon avec le modèle entraîné\ndef generer(poids, n=10):\n    resultats = []\n    for _ in range(n):\n        pokemon = \"\"\n        lettre = \".\"\n        for _ in range(20):  # max 20 lettres\n            p = calculer_probas(poids, lettre)\n            choix = list(p.keys())\n            probs = list(p.values())\n            lettre = random.choices(choix, weights=probs, k=1)[0]\n            if lettre == \".\":\n                break\n            pokemon += lettre\n        if pokemon:\n            resultats.append(pokemon.capitalize())\n    return resultats\n\n\nprint(\"Noms de Pokémon inventés après entraînement :\")\nfor p in generer(poids, 10):\n    print(f\"  {p}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce qu'on a appris\n",
    "\n",
    "- La **loss** mesure à quel point le modèle se trompe\n",
    "- Les **poids** sont les nombres que le modèle ajuste pour apprendre\n",
    "- L'**entraînement** = ajuster les poids pour réduire la loss, encore et encore\n",
    "- Même un modèle simple s'améliore avec l'entraînement !\n",
    "\n",
    "### Limite\n",
    "\n",
    "Notre modèle ne regarde encore que **1 lettre en arrière**.\n",
    "Dans la prochaine leçon, on va lui donner une **mémoire** pour qu'il\n",
    "se souvienne de plusieurs lettres à la fois.\n",
    "\n",
    "---\n",
    "*Prochaine leçon : [03 - La mémoire du modèle](03_la_memoire_du_modele.ipynb)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n### Sources (ISO 42001)\n\n- **Cross-entropy loss et descente de gradient** : [microgpt.py](https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95) — Andrej Karpathy, lignes implémentant le backward pass\n- **Analogie du gradient comme correction** : [Vidéo \"Let's build GPT\"](https://www.youtube.com/watch?v=kCc8FmEb1nY) — Andrej Karpathy (2023)\n- **Visualisation de la descente de gradient** : [3Blue1Brown - Gradient descent](https://www.youtube.com/watch?v=IHZwWFHWa-w) — Grant Sanderson\n- **Dataset Pokémon** : (c) Nintendo / Creatures Inc. / GAME FREAK inc., usage éducatif. Source : [PokéAPI](https://pokeapi.co/)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
